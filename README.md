

Stack: **Unity 6.2.2f1**, **OpenXR**, **XR Plug-in Management 4.5.1**, **XR Interaction Toolkit (XRI) 3.2.1**, **Input System**.

---

# [âœ…]ğŸ§± Block 0 â€” Project & Packages (one-time)

**Goal:** Make sure the project has the correct XR + Input packages.

**Editor steps**

1. **Create / open** a 3D (URP OK) project.
2. **Project Settings â†’ XR Plug-in Management**

   * PC (if youâ€™ll test with Link): **OpenXR = ON**
   * Android (for Quest build later): **OpenXR = ON**
3. **Window â†’ Package Manager (Unity Registry)**

   * Install **XR Interaction Toolkit** (3.2.1).
   * In XRIâ€™s **Samples** (right pane): import **Starter Assets** and (optional) **XR Device Simulator**.
4. **Project Settings â†’ Player â†’ Other Settings**

   * **Active Input Handling** = **Input System (New)**.

**Why:** OpenXR is the runtime; XRI gives us Interactors/Interactables; Starter Assets give ready input actions.

**Mini-test:** Create an empty scene â†’ *Play* (no errors about Input System or OpenXR).

**Common mistakes:**

* If you still have â€œBothâ€ input systems enabled and get warnings, switch to **Input System (New)** only.

---

# [âœ…]ğŸ§± Block 1 â€” Scene Scaffold

**Goal:** Basic XR scene that compiles.

**Editor steps**

1. **File â†’ New Scene** (call it `Session6`).
2. Delete **Main Camera**.
3. **GameObject â†’ XR â†’ XR Origin (Action-based)**.
4. **GameObject â†’ XR â†’ XR Interaction Manager**.
5. **GameObject â†’ UI â†’ Event System**.
6. (Optional) **GameObject â†’ XR â†’ Device Simulator**.
7. Create **Empty** `VR` and drag the three XR objects under it (for organization).
8. **GameObject â†’ 3D Object â†’ Plane** (as floor) at (0,0,0).

**Why:** XR Origin has the tracked camera and controller anchors. Manager routes interactions. Event System enables UI.

**Mini-test:** *Play* with a headset connected (or with Device Simulator): no red errors.

**Common mistakes:**

* Donâ€™t keep the **Main Camera**; XR Origin includes its own camera.

---

# [âœ…]ğŸ§± Block 2 â€” Target Layer + Target Object

**Goal:** Make a simple object that our ray will be allowed to hit.

**Editor steps**

1. Top-right **Layers â†’ Edit Layersâ€¦** â†’ create user layer **â€œTargetâ€**.
2. **GameObject â†’ 3D Object â†’ Cube**. Rename to **Target**.
3. Set **Target**â€™s **Layer = Target**.
4. **Add Component â†’ XRSimpleInteractable** (on the Target).

**Why:** Layer filtering is a huge performance & clarity boost. Weâ€™ll make our ray only check **Target**.

**Mini-test:** The cube exists and shows **XRSimpleInteractable** in the Inspector.

**Common mistakes:**

* If you forget to put the cube on the **Target** layer, the ray (later) wonâ€™t register it.

---

# [âœ… Added on Both âœ‹]ğŸ§± Block 3 â€” Quick Ray (no code yet)

**Goal:** Prove the concept with a **built-in** ray so juniors see success immediately.

**Editor steps**

1. Expand **XR Origin (Action-based)** â†’ find children **LeftHand Controller** and **RightHand Controller**.
2. On **RightHand Controller**: **Add Component â†’ XR Ray Interactor**.
3. Also add **XR Interactor Line Visual** (to see the beam).
4. Set **XR Ray Interactor â†’ Max Raycast Distance = 6**.
5. (Weâ€™ll set mask via code in the next block, but for a smoke test, leave defaults.)

**Mini-test:** *Play*; you should see a ray (always on) from right controller. It may hit lots of thingsâ€”thatâ€™s ok for now.

**Why:** Immediate visual feedback builds confidence before coding.

**Common mistakes:**

* If the line doesnâ€™t show, ensure **XR Interactor Line Visual** is enabled and the play camera is in view of something.

---

# [âœ… Called script MySetupRayInteractors.cs]ğŸ§± Block 4 â€” Configure Rays by Script

**Goal:** Add a manager that **adds/standardizes** rays on both controllers and restricts them to the **Target** layer.

**Create script** `SetupRayInteractors.cs` (in a **Scripts** folder) and **attach** it to an empty `RaycastManager` in the scene.
In the Inspector, drag **LeftHand Controller** and **RightHand Controller** onto the fields.

```csharp
using UnityEngine;
using UnityEngine.XR.Interaction.Toolkit;

public class SetupRayInteractors : MonoBehaviour
{
    [Header("Assign controller GameObjects from XR Origin")]
    [SerializeField] private GameObject leftController;
    [SerializeField] private GameObject rightController;

    [Header("Ray Tuning")]
    [SerializeField] private float maxDistance = 6f;
    [SerializeField] private float lineWidth = 0.01f;
    [SerializeField] private string raycastLayerName = "Target";

    private void Start()
    {
        ConfigureOne(leftController);
        ConfigureOne(rightController);
    }

    private void ConfigureOne(GameObject controllerGO)
    {
        if (!controllerGO)
        {
            Debug.LogWarning("[SetupRayInteractors] Missing controller reference.");
            return;
        }

        // Ensure ray exists, start disabled (perf-friendly)
        var ray = controllerGO.GetComponent<XRRayInteractor>();
        if (!ray) ray = controllerGO.AddComponent<XRRayInteractor>();
        ray.enabled = false;
        ray.maxRaycastDistance = maxDistance;

        // Restrict to the Target layer
        int layer = LayerMask.NameToLayer(raycastLayerName);
        ray.raycastMask = (layer == -1) ? ~0 : (1 << layer);

        // Visual line
        var line = controllerGO.GetComponent<XRInteractorLineVisual>();
        if (!line) line = controllerGO.AddComponent<XRInteractorLineVisual>();
        line.lineWidth = lineWidth;
        line.enabled = true;
    }
}
```

**Why:** â€œSeparation of concerns.â€ One place controls both rays consistently (length, mask, visuals) and prevents missing components.

**Mini-test:** *Play* â†’ no ray visible (by design). Weâ€™ll enable it via input in the next block.

**Common mistakes:**

* Forgetting to assign the **Left/Right controller** GameObjects in the Inspector.

---

# [âœ… Called script MyVRInputManager.cs]ğŸ§± Block 5 â€” Input-Driven Ray (Press to show)

**Goal:** Ray appears **only while a button is held** (event-driven; saves perf).

**Create script** `VRInputManager.cs`. **Add it** to **both** controllers (Left/Right).
**Assign InputActionReference** in Inspector:

* Left â†’ `XRI LeftHand Interaction / Activate`
* Right â†’ `XRI RightHand Interaction / Activate`
  (These live in the **XRI Default Input Actions** asset you imported from Samples. Use the Project search to find them.)

```csharp
using UnityEngine;
using UnityEngine.InputSystem;
using UnityEngine.XR.Interaction.Toolkit;

public class VRInputManager : MonoBehaviour
{
    [Header("Drag the XRI ... / Activate action here")]
    [SerializeField] private InputActionReference activateAction;

    private XRRayInteractor ray;

    private void Awake()
    {
        ray = GetComponent<XRRayInteractor>();
        if (!ray)
            Debug.LogError("[VRInputManager] XRRayInteractor is required on the same GameObject.");
    }

    private void OnEnable()
    {
        if (activateAction != null)
        {
            activateAction.action.performed += OnPerformed;
            activateAction.action.canceled  += OnCanceled;
            activateAction.action.Enable();
        }

        if (ray) ray.enabled = false; // start hidden
    }

    private void OnDisable()
    {
        if (activateAction != null)
        {
            activateAction.action.performed -= OnPerformed;
            activateAction.action.canceled  -= OnCanceled;
            activateAction.action.Disable();
        }
    }

    private void OnPerformed(InputAction.CallbackContext _)
    {
        if (ray) ray.enabled = true;
    }

    private void OnCanceled(InputAction.CallbackContext _)
    {
        if (ray) ray.enabled = false;
    }
}
```

**Why:** Juniors clearly see the mapping: â€œinput event â†’ enable rayâ€. No polling in `Update()`.

**Mini-test:** *Play*. Hold **Activate** (usually Trigger/Grip per binding) â†’ ray shows; release â†’ ray hides.

**Common mistakes:**

* Assigned the wrong action (e.g., â€œSelectâ€ instead of â€œActivateâ€).
* Action reference left **None** (ray never turns on).

---

# [âœ…]ğŸ§± Block 6 â€” Visual Feedback on Hover

**Goal:** When the ray **hovers** the Target, it changes color.

**Create two materials** in your project: `DefaultMat` (any color), `HitMat` (different color).
**Create script** `SimpleTarget.cs` and **add it** to the **Target** cube.
Make sure **XRSimpleInteractable** is also on the Target.

```csharp
using UnityEngine;
using UnityEngine.XR.Interaction.Toolkit;

public class SimpleTarget : MonoBehaviour
{
    [Header("Assign materials")]
    [SerializeField] private Material defaultMaterial;
    [SerializeField] private Material hitMaterial;

    private MeshRenderer meshRenderer;
    private XRSimpleInteractable simple;

    private void Awake()
    {
        meshRenderer = GetComponent<MeshRenderer>();
        simple = GetComponent<XRSimpleInteractable>();

        if (!simple)
            Debug.LogError("[SimpleTarget] Requires XRSimpleInteractable on the same GameObject.");
    }

    private void Start()
    {
        if (meshRenderer && defaultMaterial)
            meshRenderer.material = defaultMaterial;
    }

    private void OnEnable()
    {
        if (simple != null)
        {
            simple.hoverEntered.AddListener(OnHoverEntered);
            simple.hoverExited.AddListener(OnHoverExited);
        }
    }

    private void OnDisable()
    {
        if (simple != null)
        {
            simple.hoverEntered.RemoveListener(OnHoverEntered);
            simple.hoverExited.RemoveListener(OnHoverExited);
        }
    }

    private void OnHoverEntered(HoverEnterEventArgs _)
    {
        if (meshRenderer && hitMaterial)
            meshRenderer.material = hitMaterial;
    }

    private void OnHoverExited(HoverExitEventArgs _)
    {
        if (meshRenderer && defaultMaterial)
            meshRenderer.material = defaultMaterial;
    }
}
```

**Why:** Students learn the event model: the **Interactable** fires **hover** events; our script reacts.

**Mini-test:** *Play*. Hold **Activate** to show the ray. Aim at **Target** â†’ it switches to `HitMat`. Move away â†’ reverts to `DefaultMat`.

**Common mistakes:**

* Forgot **XRSimpleInteractable** on the Target.
* Didnâ€™t assign the materials in the Inspector.

---

# [âœ…]ğŸ§± Block 7 â€” Device Simulator (No Headset)

**Goal:** Practice without a headset.

**Editor steps**

1. Ensure **XR Device Simulator** is in your scene.
2. *Play*. Use these keys (defaults):

   * **Right mouse**: look around
   * **WASD / QE**: move
   * **1/2**: switch devices [âœï¸T/Y worked for me]
   * **T**: â€œselect/activateâ€ action (shows the ray) [âœï¸ Left click worked for me]
   * **X**: swap between left/right hand [âœï¸tab worked for me]

**Why:** Great for students at home without a headset.

**Mini-test:** Press **T** â†’ ray appears; hover the cube â†’ color changes.

**Common mistakes:**

* Scene camera not pointed at the Target: move closer with WASD.

---

# ğŸ§± Block 8 â€” Nice Polishes (choose any)

**A) Hide Ray when nothing valid is hit**[â“ğŸ¤·Could not do it]

* On each **XRRayInteractor**, enable **Hide Raycast Line If No Hit** (or set **Line Visual â†’ â€œOnly Show When Hitâ€** style by code).
  **Why:** Cleaner UX.

**B) Per-hand responsibilities (UI vs 3D)**[â“ğŸ¤· The layer at top of inspector]

* Put UI on a **UI** layer; set **Left ray mask = UI**, **Right ray mask = Target**. 
  **Why:** Prevents â€œone ray hitting everything.â€

**C) Small reticle**[â“ğŸ¤· Reticle remain even when ray disapear]

* Add a tiny sphere at the hit point via **XR Interactor Line Visual â†’ Reticle** to help depth perception.

---

## [âœ…]Folder & Hierarchy Snapshot (for juniors)

```
Assets/
  Materials/
    DefaultMat.mat
    HitMat.mat
  Scripts/
    SetupRayInteractors.cs
    VRInputManager.cs
    SimpleTarget.cs
  XRI Samples/ (auto from package)
Scenes/
  Session6.unity

Hierarchy
â””â”€ VR
   â”œâ”€ XR Origin (Action-based)
   â”‚  â”œâ”€ Camera Offset
   â”‚  â”‚  â”œâ”€ Main Camera (from XR Origin)
   â”‚  â”‚  â”œâ”€ LeftHand Controller  (has XRRayInteractor + Line Visual + VRInputManager)
   â”‚  â”‚  â””â”€ RightHand Controller (has XRRayInteractor + Line Visual + VRInputManager)
   â”œâ”€ XR Interaction Manager
   â”œâ”€ Event System
   â””â”€ XR Device Simulator (optional)
â””â”€ RaycastManager (SetupRayInteractors)
â””â”€ Plane (floor)
â””â”€ Target (Cube, Layer=Target, XRSimpleInteractable, SimpleTarget) [â“ğŸ¤·Target the one at top of inspector or teh interaction layer mask at XRSimpleInteractable]
```

---

## What students learn (explicitly)

* **Interactor vs Interactable**: the â€œhandâ€ casts a ray; the â€œcubeâ€ responds.
* **Events, not polling**: `hoverEntered/Exited`, `performed/canceled`.
* **Separation of concerns**:

  * `SetupRayInteractors` = build/configure rays
  * `VRInputManager` = connect input â†’ enable/disable
  * `SimpleTarget` = visual feedback logic
* **Safety**: start rays **disabled** and enable only on demand (perf win).
* **Filtering**: layers keep interactions intentional and fast.

---

If you want, I can package this as a **Markdown lab sheet** (with checkboxes) or a **GitHub README** formatted exactly like your Lab-Guide repo so you can teach while building live.

